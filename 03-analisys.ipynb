{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Feature Extraction\n",
    "## Extração básica de recursos\n",
    "\n",
    "De alguma forma, devemos extrair as características do nosso sinal de áudio que são mais relevantes para o problema que estamos tentando resolver. \n",
    "\n",
    "Por exemplo, se quisermos classificar instrumentos por **timbre**, queremos características que possam nos ajudar a destinguir sons por seu **timbre** e não por seu **tom**.\n",
    "\n",
    "> Este processo é conhecido como `extração de recursos` (feature extraction).\n",
    "\n",
    "Para esta tarefa vamos analisar vinte arquivos de áudio: \n",
    "\n",
    "* dez amostras de **`kick drum`** ou **bumbo** \n",
    "* dez amostras de **`snare drum`** ou **caixa**\n",
    "\n",
    "<div align=\"center\" style=\"width: 100%;\">\n",
    "    <img src=\"imgs/drum-set-labelled.jpg\" style=\"width: 50%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kick_signals = [ librosa.load(p)[0] for p in Path().glob('audios/drum_samples/train/kick_*.mp3') ]\n",
    "snare_signals = [ librosa.load(p)[0] for p in Path().glob('audios/drum_samples/train/snare_*.mp3') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Quantidade de kick drums: {len(kick_signals)}')\n",
    "print(f'Quantidade de snare drums: {len(snare_signals)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kick drum signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "for i, x in enumerate(kick_signals):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    librosa.display.waveplot(x[:10000], alpha=0.8)\n",
    "    plt.ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Snare drum signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "for i, x in enumerate(snare_signals):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    librosa.display.waveplot(x[:10000], alpha=0.8)\n",
    "    plt.ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Feature Vector\n",
    "\n",
    "Vamos criar um vetor de recursos (Feature Vector), para armazenar nossa coleção de recursos. \n",
    "\n",
    "Abaixo temos o método `extract_features`, que é uma função simples para construção de um vetor de recursos bidimensionais a partir de um determinado sinal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(signal):\n",
    "    return [\n",
    "        librosa.feature.zero_crossing_rate(signal)[0, 0],\n",
    "        librosa.feature.spectral_centroid(signal)[0, 0],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando list comprehension para agrupar os vetores\n",
    "\n",
    "kick_features = np.array([extract_features(x) for x in kick_signals])\n",
    "snare_features = np.array([extract_features(x) for x in snare_signals])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot do histograma das características de cada uma das classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.hist(kick_features[:,0], color='b', range=(0, 0.2), alpha=0.5, bins=20)\n",
    "plt.hist(snare_features[:,0], color='r', range=(0, 0.2), alpha=0.5, bins=20)\n",
    "plt.legend(('kicks', 'snares'))\n",
    "plt.xlabel('Zero Crossing Rate')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.hist(kick_features[:,1], color='b', range=(0, 4000), bins=30, alpha=0.6)\n",
    "plt.hist(snare_features[:,1], color='r', range=(0, 4000), bins=30, alpha=0.6)\n",
    "plt.legend(('kicks', 'snares'))\n",
    "plt.xlabel('Spectral Centroid (frequency bin)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "### Dimensionamento de recursos\n",
    "\n",
    "As características que usamos no exemplo anterior incluíam a taxa de zero-crossing (zero crossing rate) e o centroide espectral (spectral centroid). Esses dois recursos são expressos usando unidades diferentes. Essa discrepância pode gerar problemas ao realizar uma classificação a posteriori. Portanto, normalizaremos cada vetor de recursos em uma faixa comum, armazenando também os parâmetros desta normalização para uso futuro.\n",
    "\n",
    "Neste caso usaremos o `sklearn.preprocessing.MinMaxScaler`, que retorna uma série de valores escalonados de tal forma que cada dimensão do recurso está na faixa de -1 a 1.\n",
    "\n",
    "Vamos concatenar todos os vetores de recursos em uma tabela de recursos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table = np.vstack((kick_features, snare_features))\n",
    "\n",
    "print(feature_table.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalar cada dimensão de recurso para a faixa entre -1 e 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "training_features = scaler.fit_transform(feature_table)\n",
    "\n",
    "print(training_features.min(axis=0))\n",
    "print(training_features.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot das características dimensionadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(training_features[:10,0], training_features[:10,1], c='b')\n",
    "plt.scatter(training_features[10:,0], training_features[10:,1], c='r')\n",
    "plt.xlabel('Zero Crossing Rate')\n",
    "plt.ylabel('Spectral Centroid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy and RMSE\n",
    "\n",
    "A energia ([Wikipedia](https://en.wikipedia.org/wiki/Energy_(signal_processing%29); FMP, p. 66) de um sinal corresponde à magntiude total do sinal. Para sinais de áudio, isso corresponde aproximadamente à intensidade do sinal. A energia em um sinal é definida como:\n",
    "\n",
    "$$\\Large \\sum_n \\left| x(n) \\right|^2$$\n",
    " \n",
    "A energia da raíz quadrática média, do inglês root-mean-square energy (RMSE), é definida por:\n",
    "\n",
    "$$\\Large \\sqrt{ \\frac{1}{N} \\sum_n \\left| x(n) \\right|^2 }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load('audios/simple_loop.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.get_duration(x, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio('audios/simple_loop.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "librosa.display.waveplot(x, sr=sr, alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computar o short-time energy usando apenas list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length = 256\n",
    "frame_length = 512\n",
    "\n",
    "energy = np.array([\n",
    "    sum(abs(x[i:i+frame_length]**2))\n",
    "    for i in range(0, len(x), hop_length)\n",
    "])\n",
    "\n",
    "print(energy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular o RMSE usando a função [librosa.feature.rms](https://librosa.github.io/librosa/generated/librosa.feature.rms.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = librosa.feature.rms(x, frame_length=frame_length, hop_length=hop_length, center=True)\n",
    "\n",
    "print(rmse.shape)\n",
    "\n",
    "rmse = rmse[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot da energia e RMSE em conjunto com a forma do sinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = range(len(energy))\n",
    "\n",
    "t = librosa.frames_to_time(frames, sr=sr, hop_length=hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "librosa.display.waveplot(x, sr=sr, alpha=0.4)\n",
    "plt.plot(t, energy/energy.max(), 'r--')             # normalized for visualization\n",
    "plt.plot(t[:len(rmse)], rmse/rmse.max(), color='g') # normalized for visualization\n",
    "plt.legend(('Energy', 'RMSE'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Crossing Rate\n",
    "### Taxa de Travessia do Zero\n",
    "\n",
    "A Taxa de Travessia do Zero do inglês [zero crossing rate](https://en.wikipedia.org/wiki/Zero-crossing_rate) (ZCR), é a taxa de alterações do sinal durante o determinado quadro de áudio. Em outras palavras, é o número de vezes que o sinal muda de valor, de positivo para negativo e vice-versa, dividido pelo comprimento do quadro. O ZCR é definido de acordo com a seguinte equação:\n",
    "\n",
    "O ZCR pode ser interpretado como uma medida da invidade de um sinal. No geral, ele exibe valores mais elevados no caso de sinais barulhentos. Também é conhecido por refletir, de forma bastante grosseira, as características espectrais de um sinal. Tais propriedades, juntamente com o fato de ser fácil de calcular, levaram à sua adoção por inúmeras aplicações, incluindo detecção de fala e classificação de gênero musical, para citar apenas alguns.\n",
    "\n",
    "> A ZCR é muito usada para detectar segmentos sonoros de curta duração. Ela assume que a energia está concentrada em baixas frequências para o sinal em questão, o que acarreta em poucas oscilações por unidade de tempo e, portanto, uma contagem baixa de passagens pelo zero. \n",
    "\n",
    "A Figura abaixo apresenta um sinal de fala junto com a respectiva sequência ZCR. Mostra que os valores do ZCR são mais elevados para as partes barulhentos do sinal, enquanto nos quadros de fala os respectivos valores ZCR são geralmente menores (dependendo, é claro, da natureza e contexto do fonema que é pronunciado a cada vez).\n",
    "\n",
    "<div align=\"center\" style=\"width: 100%;\">\n",
    "    <img src=\"imgs/zcr-in-voice.jpg\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0 = 6500\n",
    "n1 = 7500\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(x[n0:n1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar a librosa para obter a Taxa de Travessia do Zero do frame que estamos investigando. O resultado será o cálculo da máscara binária onde temos a presença de uma travessia do zero. Para encontrar o número total de travessias realizamos um sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_crossings = librosa.zero_crossings(x[n0:n1], pad=False)\n",
    "\n",
    "zero_crossings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(zero_crossings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar a ZCR ao longo do tempo, use a função zero_crossing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcrs = librosa.feature.zero_crossing_rate(x)\n",
    "\n",
    "print(zcrs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot do ZCR resultante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.plot(zcrs[0])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe como a alta taxa de cruzamento do zero corresponde à presença do snare drum. \n",
    "\n",
    "A razão para a alta taxa perto do início é porque o silêncio oscila discretamente em torno de zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(x[:1000])\n",
    "plt.ylim(-0.0001, 0.0001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um truque simples para contornar isso é adicionar uma pequena constante antes de calcular a RCS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcrs = librosa.feature.zero_crossing_rate(x + 0.0001)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(zcrs[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Features\n",
    "### Características espectrais\n",
    "\n",
    "Para classificação, vamos usar novas características em nosso arsenal: momentos espectrais (centroides, largura de banda, distorção, kurtose) e outras estatísticas espectrais.\n",
    "\n",
    "Momentos ([*Moments*](https://en.wikipedia.org/wiki/Moment_(mathematics)) é um termo usado em física e estatística. Há momentos crus e momentos centrais.\n",
    "\n",
    "Você provavelmente já está familiarizado com dois exemplos de momentos: média e variância. O primeiro momento bruto é conhecido como a média. O segundo momento central é conhecido como variância.\n",
    "\n",
    "### Espectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load('audios/simple_loop.wav')\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O centroide espectral (**spectral centroid** [Wikipedia](https://en.wikipedia.org/wiki/Spectral_centroid)) indica em que frequência a energia de um espectro é centrada. Isto é como uma média ponderada:\n",
    "\n",
    "$$ f_c = \\frac{\\sum_k S(k) f(k)}{\\sum_k S(k)} $$\n",
    "\n",
    "Onde $S(k)$ é a magnitude espectral da frequência quando o bin for $k$, e $f(k)$ é a frequência do bin $k$.\n",
    "\n",
    "[`librosa.feature.spectral_centroid`](https://librosa.github.io/librosa/generated/librosa.feature.spectral_centroid.html#librosa.feature.spectral_centroid) computa o centroide espectral para cada frame do sinal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\n",
    "spectral_centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule a variável de tempo para visualização:\n",
    "\n",
    "frames = range(len(spectral_centroids))\n",
    "t = librosa.frames_to_time(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina uma função para normalizar o centroide espectral para ajustar a visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot do centroide espectral junto com a forma do sinal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "librosa.display.waveplot(x, sr=sr, alpha=0.4)\n",
    "plt.plot(t, normalize(spectral_centroids), color='r') # normalize for visualization purposes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semelhante à taxa de travessia zero, há um aumento espúrio no centroide espectral no início do sinal. Isso porque o silêncio no início tem uma amplitude tão pequena que os componentes de alta frequência têm a chance de dominar. Um hack em torno disso é adicionar uma pequena constante antes de calcular o centroide espectral, mudando assim o centroide para zero em porções tranquilas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "spectral_centroids = librosa.feature.spectral_centroid(x+0.01, sr=sr)[0]\n",
    "librosa.display.waveplot(x, sr=sr, alpha=0.4)\n",
    "plt.plot(t, normalize(spectral_centroids), color='r') # normalize for visualization purposes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Transform\n",
    "### Transformada de Fourier\n",
    "\n",
    "A Transformada de Fourier ([Wikipedia](https://en.wikipedia.org/wiki/Fourier_transform)) é uma das operações mais fundamentais no processamento de sinal e matemática aplicada.\n",
    "\n",
    "Ele transforma nosso sinal no domínio do tempo para o domínio da frequência. Enquanto o domínio do tempo expressa nosso sinal como uma sequência de amostras, o domínio da frequência expressa nosso sinal como uma superposição de sinusóides de magnitudes, frequências e compensações de fase variáveis.\n",
    "\n",
    "Para calcular a Transformada de Fourier em NumPy ou SciPy, use [scipy.fft](http://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.fft.html#scipy.fftpack.fft):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load('audios/c_strum.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape) \n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scipy.fft(x)\n",
    "X_mag = np.absolute(X)\n",
    "f = np.linspace(0, sr, len(X_mag)) # frequency variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot do espectro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 5))\n",
    "plt.plot(f, X_mag) # magnitude spectrum\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoom in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 5))\n",
    "plt.plot(f[:5000], X_mag[:5000])\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short-Time Fourier Transform\n",
    "### Transformada de fourier de curto prazo\n",
    "\n",
    "Os sinais musicais são altamente não estacionários, ou seja, suas estatísticas mudam ao longo do tempo. Seria um tanto sem sentido calcular uma única transformação de Fourier ao longo de uma música inteira de 10 minutos.\n",
    "\n",
    "A transformada de Fourier de curta duração (STFT) (Wikipedia; FMP, p. 53) é obtida calculando a transformada de Fourier para quadros sucessivos em um sinal.\n",
    "\n",
    "$$\\Large X(m, \\omega) = \\sum_n x(n) w(n-m) e^{-j \\omega n} $$\n",
    "\n",
    "À medida que aumentamos  $\\large m$, nós deslizamos a janela da função $\\large w$ à direita. Para o quadro resultante, $\\large x(n) w(n-m)$, nós calculamos a transformada de Fourier. Logo, o STFT $\\large X$ é uma função tanto para o tempo ($\\large m$), quanto a frequência ($\\large \\omega$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load('audios/brahms_hungarian_dance_5.mp3')\n",
    "\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize o [librosa.stft](https://librosa.github.io/librosa/generated/librosa.core.stft.html#librosa.core.stft) para computar o STFT.\n",
    "\n",
    "Nós informamos o frame size, ou seja, o tamanho da FFT, e um hop length, ou seja, o valor que deve ser incrementado ao frame size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length = 512\n",
    "n_fft = 2048\n",
    "X = librosa.stft(x, n_fft=n_fft, hop_length=hop_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converte o **comprimento do salto** (hop length) e o tamanho do quadro (frame size) em segundos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(hop_length)/sr # units of seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(n_fft)/sr  # units of seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para sinais reais, a transformação de Fourier é simétrica sobre o ponto médio. Portanto, só retém metade da saída: librosa.stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em nosso exemplo, o STFT gerou 1025 frequency bins e 9813 frames.\n",
    "\n",
    "## Spectrogram\n",
    "### Espectrograma\n",
    "\n",
    "No processamento de áudio, muitas vezes só nos preocupamos com a magnitude espectral e não com o conteúdo de fase em análise.\n",
    "\n",
    "O Espectrograma ([Wikipedia](https://en.wikipedia.org/wiki/Spectrogram); FMP, p. 29, 55) mostra a intensidade das frequências ao longo do tempo. Um espectrograma é simplesmente a magnitude quadrada do STFT:\n",
    "\n",
    "$$\\Large S(m, \\omega) = \\left| X(m, \\omega) \\right|^2$$\n",
    "\n",
    "A percepção humana da intensidade sonora é logarítmica na natureza. Portanto, muitas vezes estamos interessados na amplitude do áudio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = librosa.amplitude_to_db(abs(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para exibir o espectrograma via librosa: [librosa.display.specshow](http://bmcfee.github.io/librosa/generated/librosa.display.specshow.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "librosa.display.specshow(S, sr=sr, hop_length=hop_length, x_axis='time', y_axis='linear')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel-spectrogram\n",
    "\n",
    "[librosa.feature.melspectrogram](http://bmcfee.github.io/librosa/generated/librosa.feature.melspectrogram.html#librosa.feature.melspectrogram):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length = 256\n",
    "S = librosa.feature.melspectrogram(x, sr=sr, n_fft=4096, hop_length=hop_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A percepção humana da intensidade sonora é logarítmica por natureza. Portanto, como o espectrograma baseado no STFT, muitas vezes estamos interessados na amplitude log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logS = librosa.power_to_db(abs(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "librosa.display.specshow(logS, sr=sr, hop_length=hop_length, x_axis='time', y_axis='mel')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Mel scale](https://en.wikipedia.org/wiki/Mel_scale) é similar a função $\\log (1 + f)$:\n",
    "\n",
    "$$m = 2595 \\log_{10} \\left(1 + \\frac{f}{700} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelation\n",
    "### Autocorrelação\n",
    "\n",
    "A autocorrelação ([autocorrelation](http://en.wikipedia.org/wiki/Autocorrelation)) de um sinal descreve a semelhança de um sinal contra uma versão diferenciada de tempo de si mesmo. Para um sinal $x$, a autocorrelação $r$ é:\n",
    "\n",
    "$$ r(k) = \\sum_n x(n) x(n-k) $$, onde $k$ é frequentemente chamado de parâmetro **lag**. \n",
    "\n",
    "The autocorrelation is useful for finding repeated patterns in a signal. For example, at short lags, the autocorrelation can tell us something about the signal's fundamental frequency. For longer lags, the autocorrelation may tell us something about the tempo of a musical signal.\n",
    "\n",
    "A autocorrelação é útil para encontrar padrões repetidos em um sinal. Por exemplo, em problemas de defasagem curta, a autocorrelação pode nos dizer algo sobre a frequência fundamental do sinal. Para atrasos mais longos, a autocorrelação pode nos dizer coisas como informações sobre o ritmo de um sinal musical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load('audios/c_strum.wav')\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(x, sr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `numpy.correlate`\n",
    "\n",
    "Há duas maneiras de calcular a autocorrelação em Python. O primeiro é o método [`numpy.correlate`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.correlate.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the autocorrelation produces a symmetric signal, we only care about the \"right half\".\n",
    "\n",
    "r = np.correlate(x, x, mode='full')[len(x)-1:]\n",
    "print(x.shape, r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the autocorrelation:\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(r[:10000])\n",
    "plt.xlabel('Lag (samples)')\n",
    "plt.xlim(0, 10000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `librosa.autocorrelate`\n",
    "\n",
    "O segundo método é utilizar diretamente o [`librosa.autocorrelate`](http://bmcfee.github.io/librosa/generated/librosa.core.autocorrelate.html#librosa.core.autocorrelate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = librosa.autocorrelate(x, max_size=10000)\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(r)\n",
    "plt.xlabel('Lag (samples)')\n",
    "plt.xlim(0, 10000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`librosa.autocorrelate` convenientemente só mantém metade da função de autocorrelação, uma vez que a função de autocorrelação é simétrica. Além disso, a utilização do parâmetro `max_size` evita cálculos.\n",
    "\n",
    "## Pitch Estimation\n",
    "\n",
    "A autocorrelação é usada para encontrar padrões repetidos dentro de um sinal. Para sinais musicais, um padrão repetido pode corresponder a um período de pitch, ou no geral, o tom da música. \n",
    "\n",
    "Podemos, portanto, usar a função de autocorrelação para estimar o tom em um sinal musical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load('audios/oboe_c6.wav')\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot the autocorrelation:\n",
    "\n",
    "r = librosa.autocorrelate(x, max_size=5000)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(r[:200])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autocorrelation always has a maximum at zero, i.e. zero lag. We want to identify the maximum outside of the peak centered at zero. Therefore, we might choose only to search within a range of reasonable pitches:\n",
    "\n",
    "A autocorrelação sempre tem um máximo de zero, ou seja, zero lag. Queremos identificar o máximo fora do pico centrado em zero. Portanto, podemos escolher apenas pesquisar dentro de uma gama de arremessos razoáveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_hi = 120.0\n",
    "midi_lo = 12.0\n",
    "f_hi = librosa.midi_to_hz(midi_hi)\n",
    "f_lo = librosa.midi_to_hz(midi_lo)\n",
    "t_lo = sr/f_hi\n",
    "t_hi = sr/f_lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f_lo, f_hi)\n",
    "print(t_lo, t_hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir os pontos/tons inválidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[:int(t_lo)] = 0\n",
    "r[int(t_hi):] = 0\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(r[:1400])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontra o ponto de valor máximo:\n",
    "\n",
    "t_max = r.argmax()\n",
    "print(t_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste ponto, vamos estimar o **tom** em Hertz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(sr)/t_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na verdade, isso é muito próximo da frequência real de um **C6**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.midi_to_hz(84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"width: 100%;\">\n",
    "    <img src=\"imgs/piano-scale-hertz-frequency-notes.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"width: 100%;\">\n",
    "    <img src=\"http://newt.phys.unsw.edu.au/jw/graphics/notes.GIF\">\n",
    "   \n",
    "    ref: http://newt.phys.unsw.edu.au/jw/notes.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre Recognition\n",
    "\n",
    "Carregando 30 segundos para verificação/exploração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_brahms = 'audios/brahms_hungarian_dance_5.mp3'\n",
    "\n",
    "x_brahms, sr_brahms = librosa.load(filename_brahms, duration=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_busta = 'audios/busta_rhymes_hits_for_days.mp3'\n",
    "\n",
    "x_busta, sr_busta = librosa.load(filename_busta, duration=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x_brahms, rate=sr_brahms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x_busta, rate=sr_busta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibir o formato da onda no domínio do tempo dos sinais de áudio em análise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 4))\n",
    "librosa.display.waveplot(x_brahms, sr_brahms)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 4))\n",
    "librosa.display.waveplot(x_busta, sr_busta)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computar o melspectrogram de potência:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_brahms = librosa.feature.melspectrogram(x_brahms, sr=sr_brahms, power=2.0)\n",
    "S_busta = librosa.feature.melspectrogram(x_busta, sr=sr_busta, power=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converter amplitude em decibéis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sdb_brahms = librosa.power_to_db(S_brahms)\n",
    "Sdb_busta = librosa.power_to_db(S_busta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "librosa.display.specshow(Sdb_brahms, sr=sr_brahms, x_axis='time', y_axis='mel')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "librosa.display.specshow(Sdb_busta, sr=sr_busta, x_axis='time', y_axis='mel')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
